{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Amazon Sagemaker Reinforcement Learning demo</h1>\n",
    "<h2 style=\"margin-top: 0.1em; font-weight: normal;\"><em>Reinforcement Learning Algorithm Launcher</em></h2>\n",
    "\n",
    "Amazon AWS Sagemaker provides two manners to execute the RL algorithms:\n",
    "- **local** - the training is executed on the same instance on which the notebook is running (e.g. ml.t2.medium) which offer good performances for prototyping/initial tests.\n",
    "- **dedicated instance** - training is executed as a job on a dedicated *ml* instance (e.g. ml.m5.large - more infomation can be read at https://aws.amazon.com/sagemaker/pricing/instance-types/). These instances are suited for production environment, so that they should be employed only when the algorithm is able to comple a simple training task. In addition, remember to take into account that only certain instances provide GPU support.\n",
    "\n",
    "This notebook offers the code to run your own RL algorithm either locally or on a dedicated instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.rl import RLEstimator, RLToolkit, RLFramework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select in which AWS S3 bucket store\n",
    "# the trained model (e.g. 'fruitpunch-sagemaker-test')\n",
    "S3_BUCKET = <bucket-name>\n",
    "\n",
    "# Amazon AWS account ID\n",
    "ACCOUNT_ID = <012345678901>\n",
    "\n",
    "# select in which region the algorithm container\n",
    "# is be stored (e.g. 'eu-west-1')\n",
    "REGION = 'eu-west-1'\n",
    "\n",
    "# name of the repository on AWS ECR service where\n",
    "# the image is stored (e.g. fruitpunchai/tf-mlagents)\n",
    "REPOSITORY_NAME = 'fruitpunchai/tf-mlagents'\n",
    "\n",
    "# Optional: the username of the account employed to run\n",
    "# locally the training job (associated to the arn)\n",
    "USERNAME = <fruitpunch>\n",
    "\n",
    "# select the type of execution\n",
    "LOCAL = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `LOCAL` above selects whether the training should be done locally or on a dedicated instance. In the former case, a specific role has to be provided, which corresponds to the *arn* of a user owning the permissions for accessing both Sagemaker and S3 services. The *arn* can be retrieved from the [IAM management console](https://console.aws.amazon.com/iam/home#/users), selecting the desired user from the list.  \n",
    "In the latter case, the role can be determined automatically by Sagemaker library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_output_path = 's3://{}/'.format(S3_BUCKET)\n",
    "image_name = '{}.dkr.ecr.{}.amazonaws.com/{}:latest'.format(ACCOUNT_ID, REGION, REPOSITORY_NAME)\n",
    "\n",
    "if LOCAL:\n",
    "    train_type = 'local'\n",
    "    role = 'arn:aws:iam::{}:user/{}'.format(ACCOUNT_ID, USERNAME)\n",
    "else:\n",
    "    train_type = 'ml.m5.large' # different train instances can be chosen, depending on the budget\n",
    "    role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script hyperparameters\n",
    "If implemented by the entry point script, it is possible to pass different hyperparameters to each training job. It is sufficient to update the hyperparameters dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_dict = {\n",
    "    \"hyper-param-example\": \"This is an example of hyperparameter\",\n",
    "    \"maximum-limit-of-everything\": 7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and launching the algorithm\n",
    "The RLEstimator class provide all the necessary details to run the training job. Below are reported the main parameters that have to be configured:\n",
    "- `entry_point`: the path of the file that contains the training algorithm\n",
    "- `source_dir`: the base directory from which the entry point file is searched\n",
    "- `image_name`: the name of the custom TensorFlow image tailored to run the training algorithm\n",
    "- `role`: which AWS role is going to be associated to the training job (the role should have permissions granted to both *Sagemaker* and *S3* services)\n",
    "- `train_instance_count`: the number of instances to spawn for running the training job\n",
    "- `train_instance_type`: select whether to run locally or on a specified dedicated instance\n",
    "- `train_max_run`: the maximum number of seconds that the training job is allowed to run (default: 1 day)\n",
    "- `base_job_name`: the prefix name of the training job (it has to satisfy the following regular expression: `^[a-zA-Z0-9](-*[a-zA-Z0-9])*`)\n",
    "- `hyperparameters` a dictionary containing the hyperparameters that will be used for training the agents\n",
    "- `output_path`: the url of the S3 bucket where the content of container `/opt/ml/model` and `/opt/ml/output` directory will be saved\n",
    "\n",
    "More information regarding parameters configuration can be found on AWS Sagemaker Python SDK documentation, where [RLEstimator](https://sagemaker.readthedocs.io/en/stable/sagemaker.rl.html) and the more general [Estimator](https://sagemaker.readthedocs.io/en/stable/estimators.html) class are detailed. However, for most use cases, these parameters should be enough for running the RL training jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-13T08:59:34.084092Z",
     "start_time": "2019-08-13T08:59:33.999057Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create the training job\n",
    "estimator = RLEstimator(entry_point='<trainer_file>.py',\n",
    "                        source_dir='<src-directory>',\n",
    "                        image_name=image_name,\n",
    "                        role=role,\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type=train_type,\n",
    "                        train_max_run=86400,\n",
    "                        base_job_name='<job_name>',\n",
    "                        hyperparameters=hp_dict,\n",
    "                        output_path=S3_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch the training job on selected instance\n",
    "# Note: it might take a while before it actually starts,\n",
    "# since it has to first download the custom Docker image\n",
    "estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the execution of the training job, the `fit` function will provide a brief report of job history.\n",
    "In addition, the *AWS Sagemaker* console and [*AWS CloudwWatch Management console*](https://console.aws.amazon.com/cloudwatch/home) offer more detailed tools for monitoring training job history and its logs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
